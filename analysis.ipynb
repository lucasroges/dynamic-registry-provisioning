{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msgpack\n",
    "import edge_sim_py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latency_data():\n",
    "    user_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        simulation_data = {\n",
    "            \"dataset\": log,\n",
    "            \"mean\": 0,\n",
    "            \"median\": 0,\n",
    "            \"p95\": 0\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        user_msgpack_file = f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/User.msgpack\"\n",
    "        user_file = open(user_msgpack_file, \"rb\")\n",
    "        user_msgpack = msgpack.load(user_file)\n",
    "        user_df = pd.DataFrame(user_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        latency = user_df[[\"Object\", \"Delays\"]]\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[\"mean\"] = latency[\"Delays\"].mean()\n",
    "        simulation_data[\"median\"] = latency[\"Delays\"].median()\n",
    "        simulation_data[\"p95\"] = latency[\"Delays\"].quantile(0.95)\n",
    "\n",
    "        # Closing file\n",
    "        user_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        user_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provisioning Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provisioning_time_data(step):\n",
    "    service_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        simulation_data = {\n",
    "            \"dataset\": log,\n",
    "            \"mean (total)\": 0,\n",
    "            \"mean (w/o cache)\": 0,\n",
    "            \"median (total)\": 0,\n",
    "            \"median (w/o cache)\": 0,\n",
    "            \"p95 (total)\": 0,\n",
    "            \"p95 (w/o cache)\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        service_msgpack_file = f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/Service.msgpack\"\n",
    "        service_file = open(service_msgpack_file, \"rb\")\n",
    "        service_msgpack = msgpack.load(service_file)\n",
    "        service_df = pd.DataFrame(service_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        migrations_last_step = service_df[service_df[\"Time Step\"] == step][[\"Object\", \"Average Migration Duration\", \"Average Migration Without Using Cache Duration\"]]\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[f\"mean (total)\"] = migrations_last_step[\"Average Migration Duration\"].mean()\n",
    "        simulation_data[f\"mean (w/o cache)\"] = migrations_last_step[\"Average Migration Without Using Cache Duration\"].mean()\n",
    "        simulation_data[f\"median (total)\"] = migrations_last_step[\"Average Migration Duration\"].median()\n",
    "        simulation_data[f\"median (w/o cache)\"] = migrations_last_step[\"Average Migration Without Using Cache Duration\"].median()\n",
    "        simulation_data[f\"p95 (total)\"] = migrations_last_step[\"Average Migration Duration\"].quantile(0.95)\n",
    "        simulation_data[f\"p95 (w/o cache)\"] = migrations_last_step[\"Average Migration Without Using Cache Duration\"].quantile(0.95)\n",
    "\n",
    "        # Closing file\n",
    "        service_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        service_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(service_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Reallocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reallocations_data(step):\n",
    "    service_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        simulation_data = {\n",
    "            \"dataset\": log,\n",
    "            \"total\": 0,\n",
    "            \"w/o cache\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        service_msgpack_file = f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/Service.msgpack\"\n",
    "        service_file = open(service_msgpack_file, \"rb\")\n",
    "        service_msgpack = msgpack.load(service_file)\n",
    "        service_df = pd.DataFrame(service_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        migrations_last_step = service_df[service_df[\"Time Step\"] == step][[\"Object\", \"Number of Finished Migrations\", \"Number of Finished Migrations Without Using Cache\"]]\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[f\"total\"] = migrations_last_step[\"Number of Finished Migrations\"].sum()\n",
    "        simulation_data[f\"w/o cache\"] = migrations_last_step[\"Number of Finished Migrations Without Using Cache\"].sum()\n",
    "\n",
    "        # Closing file\n",
    "        service_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        service_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(service_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registry Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_registry_usage_data():\n",
    "    registry_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        simulation_data = {\n",
    "            \"dataset\": log,\n",
    "            \"mean\": 0,\n",
    "            \"median\": 0,\n",
    "            \"p95\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        registry_msgpack_file = f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/ContainerRegistry.msgpack\"\n",
    "        registry_file = open(registry_msgpack_file, \"rb\")\n",
    "        registry_msgpack = msgpack.load(registry_file)\n",
    "        registry_df = pd.DataFrame(registry_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        registry_filtered_data = (\n",
    "            registry_df[registry_df[\"P2P\"] == True][[\"Object\", \"Provisioning\", \"Not Provisioning\"]]\n",
    "            if log[1] == \"p2p\"\n",
    "            else registry_df[[\"Object\", \"Provisioning\", \"Not Provisioning\"]]\n",
    "        )\n",
    "        registry_data_grouped = registry_filtered_data.groupby(\"Object\").sum()\n",
    "        registry_data_grouped[\"Total Steps\"] = registry_data_grouped.sum(axis=1)\n",
    "        registry_data_grouped[\"Provisioning Percentage\"] = registry_data_grouped[\"Provisioning\"] / registry_data_grouped[\"Total Steps\"]\n",
    "        registry_data_grouped[\"Not Provisioning Percentage\"] = registry_data_grouped[\"Not Provisioning\"] / registry_data_grouped[\"Total Steps\"]\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[\"mean\"] = registry_data_grouped[\"Provisioning Percentage\"].mean()\n",
    "        simulation_data[\"median\"] = registry_data_grouped[\"Provisioning Percentage\"].median()\n",
    "        simulation_data[\"p95\"] = registry_data_grouped[\"Provisioning Percentage\"].quantile(0.95)\n",
    "\n",
    "        # Closing file\n",
    "        registry_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        registry_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(registry_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Registries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_registries_data():\n",
    "    registry_data = {}\n",
    "\n",
    "    for index, log in enumerate(logs):\n",
    "        # Opening file\n",
    "        registry_msgpack_file = f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/ContainerRegistry.msgpack\"\n",
    "        registry_file = open(registry_msgpack_file, \"rb\")\n",
    "        registry_msgpack = msgpack.load(registry_file)\n",
    "        registry_df = pd.DataFrame(registry_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        registries_per_timestep = registry_df[registry_df[\"Time Step\"] > 0].groupby([\"Time Step\"]).count()[\"Object\"]\n",
    "\n",
    "        # Persisting information\n",
    "        registry_data[labels[index].capitalize()] = registries_per_timestep\n",
    "\n",
    "        # Closing file\n",
    "        registry_file.close()\n",
    "\n",
    "    registries_per_timestep_df = pd.concat(registry_data, axis=1)\n",
    "\n",
    "    return registries_per_timestep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cpu_and_memory(cpu, memory) -> float:\n",
    "    \"\"\"Normalizes the CPU and memory values.\n",
    "\n",
    "    Args:\n",
    "        cpu (float): CPU value.\n",
    "        memory (float): Memory value.\n",
    "\n",
    "    Returns:\n",
    "        normalized_value (float): Normalized value.\n",
    "    \"\"\"\n",
    "    normalized_value = (cpu * memory) ** (1 / 2)\n",
    "    return normalized_value\n",
    "\n",
    "def get_server_utilization_data():\n",
    "    server_data = {}\n",
    "\n",
    "    for index, log in enumerate(logs):\n",
    "        # Opening file\n",
    "        server_msgpack_file = f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/EdgeServer.msgpack\"\n",
    "        server_file = open(server_msgpack_file, \"rb\")\n",
    "        server_msgpack = msgpack.load(server_file)\n",
    "        server_df = pd.DataFrame(server_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        server_df = server_df[[\"Object\", \"CPU\", \"RAM\", \"CPU Demand\", \"RAM Demand\", \"Time Step\"]]\n",
    "        server_df[\"Normalized Utilization\"] = server_df.apply(lambda row: normalize_cpu_and_memory(row[\"CPU Demand\"], row[\"RAM Demand\"])/normalize_cpu_and_memory(row[\"CPU\"], row[\"RAM\"]), axis=1)\n",
    "        \n",
    "        server_per_timestep = server_df[server_df[\"Time Step\"] > 0].groupby([\"Time Step\"])[\"Normalized Utilization\"].mean()\n",
    "\n",
    "        # Persisting information\n",
    "        server_data[labels[index].capitalize()] = server_per_timestep\n",
    "\n",
    "        # Closing file\n",
    "        server_file.close()\n",
    "\n",
    "    return pd.concat(server_data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_x(x, width, i, n):\n",
    "    return x + width * (i - n / 2) + width / 2\n",
    "\n",
    "\n",
    "def plot_data_with_grouped_bar(\n",
    "    keys: list,\n",
    "    data: pd.DataFrame,\n",
    "    xlabel: str,\n",
    "    ylabel: str,\n",
    "    bbox_to_anchor: tuple,\n",
    "    yscale: str = \"linear\",\n",
    "    yticks: list = None,\n",
    "):\n",
    "    # Plotting bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    width = 0.8\n",
    "\n",
    "    hatches = [\"\", \"/\", \"|\", \"\\\\\", \"x\", \"o\"]\n",
    "\n",
    "    x = np.arange(len(data))\n",
    "\n",
    "    for key in keys:\n",
    "        ax.bar(\n",
    "            x=calculate_x(x, width/len(keys), keys.index(key), len(keys)),\n",
    "            height=data[key],\n",
    "            width=width/len(keys),\n",
    "            label=key.title(),\n",
    "            hatch=hatches.pop(0),\n",
    "            color=\"#aaaaaa\",\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=2,\n",
    "            error_kw={\"elinewidth\": 2, \"capthick\": 2, \"capsize\": 5}\n",
    "        )\n",
    "\n",
    "    # Setting labels and ticks\n",
    "    ax.legend(fontsize=20, bbox_to_anchor=bbox_to_anchor, loc=\"upper center\", ncol=2)\n",
    "    ax.set_xlabel(xlabel, fontsize=24, fontweight=\"bold\", labelpad=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=24, fontweight=\"bold\", labelpad=10, loc=\"center\")\n",
    "    ax.set_xticks(x, labels)\n",
    "    ax.tick_params(axis=\"x\", labelsize=24)\n",
    "    ax.tick_params(axis=\"y\", labelsize=24)\n",
    "    ax.set_yscale(yscale)\n",
    "    if yscale == \"log\":\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.get_yaxis().set_major_formatter(mtick.ScalarFormatter())\n",
    "    if ylabel == \"% of Steps Active\":\n",
    "        ax.get_yaxis().set_major_formatter(mtick.PercentFormatter(1.0, decimals=0))\n",
    "\n",
    "    # Saving figure\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_over_time(\n",
    "    labels: list,\n",
    "    data: pd.DataFrame,\n",
    "    xlabel: str,\n",
    "    ylabel: str,\n",
    "    bbox_to_anchor,\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=24, fontweight=\"bold\", labelpad=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=24, fontweight=\"bold\", labelpad=10, loc=\"center\")\n",
    "    ax.tick_params(axis=\"x\", labelsize=24)\n",
    "    ax.tick_params(axis=\"y\", labelsize=24)\n",
    "\n",
    "    p = ax.plot(\n",
    "        data,\n",
    "        linewidth=2,\n",
    "    )\n",
    "\n",
    "    # Adding legend\n",
    "    ax.legend(labels, fontsize=20, bbox_to_anchor=bbox_to_anchor, loc=\"upper center\", ncol=3)\n",
    "\n",
    "    # Saving figure\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"logs\"\n",
    "\n",
    "last_step = 3600\n",
    "\n",
    "logs = [\n",
    "    (\"central\", \"central\"),\n",
    "    (\"community\", \"community\"),\n",
    "    (\"p2p\", \"p2p\"),\n",
    "    (\"dynamic\", \"p2p\"),\n",
    "]\n",
    "\n",
    "seed = \"1\"\n",
    "\n",
    "labels = [\"Central\", \"Community\", \"P2P\", \"Dynamic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_df = get_latency_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_with_grouped_bar(\n",
    "    [\"mean\", \"median\", \"p95\"],\n",
    "    latency_df,\n",
    "    \"Registry Provisioning Strategy\",\n",
    "    \"Latency\",\n",
    "    (0.5, 1.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provisioning Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provisioning_time_df = get_provisioning_time_data(last_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provisioning_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_with_grouped_bar(\n",
    "    [\"mean (total)\", \"mean (w/o cache)\", \"median (total)\", \"median (w/o cache)\", \"p95 (total)\", \"p95 (w/o cache)\"],\n",
    "    provisioning_time_df,\n",
    "    \"Registry Provisioning Strategy\",\n",
    "    \"Provisioning Time\",\n",
    "    (0.5, 1.2)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service reallocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallocations_df = get_reallocations_data(last_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallocations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_with_grouped_bar(\n",
    "    [\"total\", \"w/o cache\"],\n",
    "    reallocations_df,\n",
    "    \"Registry Provisioning Strategy\",\n",
    "    \"Service Reallocations\",\n",
    "    (0.5, 1.35),\n",
    "    \"log\",\n",
    "    [100, 1000, 10000]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registry Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_usage_df = get_registry_usage_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_usage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_with_grouped_bar(\n",
    "    [\"mean\", \"median\", \"p95\"],\n",
    "    registry_usage_df,\n",
    "    \"Registry Provisioning Strategy\",\n",
    "    \"% of Steps Active\",\n",
    "    (0.5, 1.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of registries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_registries_df = get_number_of_registries_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_over_time(\n",
    "    labels,\n",
    "    number_of_registries_df,\n",
    "    \"Time Steps\",\n",
    "    \"Number of Registries\",\n",
    "    (0.5, 1.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_utilization_df = get_server_utilization_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_over_time(\n",
    "    labels,\n",
    "    server_utilization_df,\n",
    "    \"Time Steps\",\n",
    "    \"Server Utilization\",\n",
    "    (0.5, 1.2)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
