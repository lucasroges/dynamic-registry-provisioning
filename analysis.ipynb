{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import msgpack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"logs\"\n",
    "\n",
    "last_step = 3600\n",
    "\n",
    "variations = [\n",
    "    \"nodes=100;unique_images=08\",\n",
    "    \"nodes=100;unique_images=32\",\n",
    "    \"nodes=196;unique_images=16\",\n",
    "    \"nodes=196;unique_images=64\",\n",
    "]\n",
    "\n",
    "logs = [\n",
    "    (\"central\", \"central;{variation}\"),\n",
    "    (\"community\", \"community12p;{variation}\"),\n",
    "    (\"community\", \"community25p;{variation}\"),\n",
    "    (\"p2p\", \"p2p;{variation}\"),\n",
    "    (\"dynamic\", \"p2p;{variation}\"),\n",
    "    (\"resource_aware_dynamic\", \"p2p;{variation}\", \"1\"),\n",
    "    (\"resource_aware_dynamic\", \"p2p;{variation}\", \"2\"),\n",
    "    (\"resource_aware_dynamic\", \"p2p;{variation}\", \"3\"),\n",
    "    (\"resource_aware_dynamic\", \"p2p;{variation}\", \"4\"),\n",
    "]\n",
    "\n",
    "seed = \"1\"\n",
    "\n",
    "algorithm_map = {\n",
    "    \"central\": \"Central\",\n",
    "    \"community\": \"Comm.\",\n",
    "    \"p2p\": \"P2P\",\n",
    "    \"dynamic\": \"LM Dyn.\",\n",
    "    \"resource_aware_dynamic\": \"RR Dyn.\",\n",
    "}\n",
    "\n",
    "algorithm_labels = [\"Central\", \"Comm. (12%)\", \"Comm. (25%)\", \"P2P\", \"LM Dyn.\", \"RR Dyn. (1)\", \"RR Dyn. (2)\", \"RR Dyn. (3)\", \"RR Dyn. (4)\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latency_data(variation, user_type=None):\n",
    "    user_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation=variation)\n",
    "\n",
    "        simulation_data = {\n",
    "            \"Algorithm\": f\"{algorithm_map[log[0]]}\" if len(log) == 2 else f\"{algorithm_map[log[0]]} ({log[2]})\",\n",
    "            \"Mean\": 0,\n",
    "            \"Sum\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        user_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/User.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/User.msgpack\"\n",
    "        )\n",
    "        user_file = open(user_msgpack_file, \"rb\")\n",
    "        user_msgpack = msgpack.load(user_file)\n",
    "        user_df = pd.DataFrame(user_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        latency = (\n",
    "            user_df[[\"Object\", \"Delays\"]]\n",
    "            if user_type is None\n",
    "            else user_df[user_df[\"User Type\"] == user_type][[\"Object\", \"Delays\"]]\n",
    "        )\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[\"Delays\"] = latency[\"Delays\"]\n",
    "        simulation_data[\"Mean\"] = latency[\"Delays\"].mean()\n",
    "        simulation_data[\"Sum\"] = latency[\"Delays\"].sum()\n",
    "\n",
    "        # Closing file\n",
    "        user_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        user_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provisioning Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provisioning_time_data(step, variation):\n",
    "    service_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation=variation)\n",
    "\n",
    "        simulation_data = {\n",
    "            \"Algorithm\": f\"{algorithm_map[log[0]]}\" if len(log) == 2 else f\"{algorithm_map[log[0]]} ({log[2]})\",\n",
    "            \"Prov. Time Values\": [],\n",
    "            \"Mean\": 0,\n",
    "            \"Sum\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        service_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/Service.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/Service.msgpack\"\n",
    "        )\n",
    "        service_file = open(service_msgpack_file, \"rb\")\n",
    "        service_msgpack = msgpack.load(service_file)\n",
    "        service_df = pd.DataFrame(service_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        migrations_duration = service_df[service_df[\"Time Step\"] == step][\"Migrations Duration\"].apply(pd.Series).stack().reset_index(drop=True)\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[\"Prov. Time Values\"] = service_df[service_df[\"Time Step\"] == step][\"Migrations Duration\"].apply(pd.Series).stack().reset_index(drop=True)\n",
    "        simulation_data[\"Mean\"] = migrations_duration.mean()\n",
    "        simulation_data[\"Sum\"] = migrations_duration.sum()\n",
    "\n",
    "        # Closing file\n",
    "        service_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        service_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(service_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Reallocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reallocations_data(step, variation):\n",
    "    service_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation=variation)\n",
    "\n",
    "        simulation_data = {\n",
    "            \"Algorithm\": f\"{algorithm_map[log[0]]}\" if len(log) == 2 else f\"{algorithm_map[log[0]]} ({log[2]})\",\n",
    "            \"Only Using Cache\": 0,\n",
    "            \"Partially Using Cache\": 0,\n",
    "            \"Not Using Cache\": 0,\n",
    "            \"Total Migrations\": 0,\n",
    "            \"Only Using Cache (%)\": 0,\n",
    "            \"Partially Using Cache (%)\": 0,\n",
    "            \"Not Using Cache (%)\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        service_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/Service.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/Service.msgpack\"\n",
    "        )\n",
    "        service_file = open(service_msgpack_file, \"rb\")\n",
    "        service_msgpack = msgpack.load(service_file)\n",
    "        service_df = pd.DataFrame(service_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        migrations_last_step = service_df[service_df[\"Time Step\"] == step][[\"Object\", \"Migrations (Only Cache)\", \"Migrations (Partial Cache)\", \"Migrations (No Cache)\"]]\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[\"Only Using Cache\"] = migrations_last_step[\"Migrations (Only Cache)\"].sum()\n",
    "        simulation_data[\"Partially Using Cache\"] = migrations_last_step[\"Migrations (Partial Cache)\"].sum()\n",
    "        simulation_data[\"Not Using Cache\"] = migrations_last_step[\"Migrations (No Cache)\"].sum()\n",
    "        simulation_data[\"Total Migrations\"] = simulation_data[\"Only Using Cache\"] + simulation_data[\"Partially Using Cache\"] + simulation_data[\"Not Using Cache\"]\n",
    "        simulation_data[\"Only Using Cache (%)\"] = simulation_data[\"Only Using Cache\"] / simulation_data[\"Total Migrations\"]\n",
    "        simulation_data[\"Partially Using Cache (%)\"] = simulation_data[\"Partially Using Cache\"] / simulation_data[\"Total Migrations\"]\n",
    "        simulation_data[\"Not Using Cache (%)\"] = simulation_data[\"Not Using Cache\"] / simulation_data[\"Total Migrations\"]\n",
    "\n",
    "        # Closing file\n",
    "        service_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        service_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(service_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registry Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_registry_usage_data(variation):\n",
    "    registry_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation=variation)\n",
    "\n",
    "        simulation_data = {\n",
    "            \"Algorithm\": f\"{algorithm_map[log[0]]}\" if len(log) == 2 else f\"{algorithm_map[log[0]]} ({log[2]})\",\n",
    "            \"Values\": [],\n",
    "            \"Values (w/o 0%)\": [],\n",
    "            \"Mean\": 0,\n",
    "            \"Total\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        registry_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/ContainerRegistry.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/ContainerRegistry.msgpack\"\n",
    "        )\n",
    "        registry_file = open(registry_msgpack_file, \"rb\")\n",
    "        registry_msgpack = msgpack.load(registry_file)\n",
    "        registry_df = pd.DataFrame(registry_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        registry_filtered_data = (\n",
    "            registry_df[registry_df[\"P2P\"] == True][[\"Object\", \"Provisioning\", \"Not Provisioning\"]]\n",
    "            if log[1] == \"p2p\"\n",
    "            else registry_df[[\"Object\", \"Provisioning\", \"Not Provisioning\"]]\n",
    "        )\n",
    "        registry_data_grouped = registry_filtered_data.groupby(\"Object\").sum()\n",
    "        registry_data_grouped[\"Total Steps\"] = registry_data_grouped.sum(axis=1)\n",
    "        registry_data_grouped[\"Provisioning Percentage\"] = registry_data_grouped[\"Provisioning\"] / registry_data_grouped[\"Total Steps\"]\n",
    "        registry_data_grouped[\"Not Provisioning Percentage\"] = registry_data_grouped[\"Not Provisioning\"] / registry_data_grouped[\"Total Steps\"]\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[\"Values\"] = registry_data_grouped[\"Provisioning Percentage\"]\n",
    "        simulation_data[\"Values (w/o 0%)\"] = registry_data_grouped[registry_data_grouped[\"Provisioning Percentage\"] > 0][\"Provisioning Percentage\"]\n",
    "        simulation_data[\"Mean\"] = registry_data_grouped[\"Provisioning Percentage\"].mean()\n",
    "        simulation_data[\"Total\"] = registry_data_grouped[\"Total Steps\"].sum()\n",
    "        \n",
    "\n",
    "        # Closing file\n",
    "        registry_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        registry_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(registry_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Registries per Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_registries_data(variation):\n",
    "    registry_data = {}\n",
    "\n",
    "    for index, log in enumerate(logs):\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation=variation)\n",
    "\n",
    "        # Opening file\n",
    "        registry_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/ContainerRegistry.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/ContainerRegistry.msgpack\"\n",
    "        )\n",
    "        registry_file = open(registry_msgpack_file, \"rb\")\n",
    "        registry_msgpack = msgpack.load(registry_file)\n",
    "        registry_df = pd.DataFrame(registry_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        registries_per_timestep = registry_df[registry_df[\"Time Step\"] > 0].groupby([\"Time Step\"]).count()[\"Object\"]\n",
    "\n",
    "        # Persisting information\n",
    "        registry_data[algorithm_labels[index]] = registries_per_timestep\n",
    "\n",
    "        # Closing file\n",
    "        registry_file.close()\n",
    "\n",
    "    registries_per_timestep_df = pd.concat(registry_data, axis=1)\n",
    "\n",
    "    return registries_per_timestep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Utilization per Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cpu_and_memory(cpu, memory) -> float:\n",
    "    \"\"\"Normalizes the CPU and memory values.\n",
    "\n",
    "    Args:\n",
    "        cpu (float): CPU value.\n",
    "        memory (float): Memory value.\n",
    "\n",
    "    Returns:\n",
    "        normalized_value (float): Normalized value.\n",
    "    \"\"\"\n",
    "    normalized_value = (cpu * memory) ** (1 / 2)\n",
    "    return normalized_value\n",
    "    \n",
    "def get_server_utilization_data(variation):\n",
    "    server_data = {}\n",
    "\n",
    "    for index, log in enumerate(logs):\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation=variation)\n",
    "        \n",
    "        # Opening file\n",
    "        server_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/EdgeServer.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/EdgeServer.msgpack\"\n",
    "        )\n",
    "        server_file = open(server_msgpack_file, \"rb\")\n",
    "        server_msgpack = msgpack.load(server_file)\n",
    "        server_df = pd.DataFrame(server_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        server_df = server_df[[\"Object\", \"CPU\", \"RAM\", \"CPU Demand\", \"RAM Demand\", \"Time Step\"]]\n",
    "        server_df[\"Normalized Utilization\"] = server_df.apply(lambda row: normalize_cpu_and_memory(row[\"CPU Demand\"], row[\"RAM Demand\"])/normalize_cpu_and_memory(row[\"CPU\"], row[\"RAM\"]), axis=1)\n",
    "        \n",
    "        server_per_timestep = server_df[server_df[\"Time Step\"] > 0].groupby([\"Time Step\"])[\"Normalized Utilization\"].mean()\n",
    "\n",
    "        # Persisting information\n",
    "        server_data[algorithm_labels[index]] = server_per_timestep\n",
    "\n",
    "        # Closing file\n",
    "        server_file.close()\n",
    "\n",
    "    return pd.concat(server_data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Replication per Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_replication_data(log, variation):\n",
    "    # Formatting log\n",
    "    log = list(log)\n",
    "    log[1] = log[1].format(variation=variation)\n",
    "    \n",
    "    # Opening file\n",
    "    topology_msgpack_file = (\n",
    "        f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/Topology.msgpack\"\n",
    "        if len (log) == 2\n",
    "        else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/Topology.msgpack\"\n",
    "    )\n",
    "    topology_file = open(topology_msgpack_file, \"rb\")\n",
    "    topology_msgpack = msgpack.load(topology_file, strict_map_key=False)\n",
    "    topology_df = pd.DataFrame(topology_msgpack)\n",
    "\n",
    "    # Collecting information\n",
    "    image_replication_data = topology_df[[\"Object\", \"Replication Data\", \"Time Step\"]]\n",
    "    image_replication_data = pd.json_normalize(image_replication_data[\"Replication Data\"]).fillna(0)\n",
    "    image_replication_data = image_replication_data.divide(image_replication_data.sum(axis=1), axis=0)\n",
    "\n",
    "    # Sort headers\n",
    "    image_replication_data = image_replication_data.reindex(sorted(image_replication_data.columns), axis=1)\n",
    "\n",
    "    # Closing file\n",
    "    topology_file.close()\n",
    "\n",
    "    return image_replication_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def get_total_disk_utilization_data(variation):\n",
    "    server_data = []\n",
    "\n",
    "    for log in logs:\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation)\n",
    "\n",
    "        simulation_data = {\n",
    "            \"Algorithm\": f\"{algorithm_map[log[0]]}\" if len(log) == 2 else f\"{algorithm_map[log[0]]} ({log[2]})\",\n",
    "            \"Total Disk Occupation\": 0,\n",
    "        }\n",
    "\n",
    "        # Opening file\n",
    "        server_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/EdgeServer.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/EdgeServer.msgpack\"\n",
    "        )\n",
    "        server_file = open(server_msgpack_file, \"rb\")\n",
    "        server_msgpack = msgpack.load(server_file)\n",
    "        server_df = pd.DataFrame(server_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        server_df = server_df[[\"Object\", \"Disk Demand\"]]\n",
    "\n",
    "        # Persisting information\n",
    "        simulation_data[\"Total Disk Occupation\"] = server_df[\"Disk Demand\"].sum()\n",
    "\n",
    "        # Closing file\n",
    "        server_file.close()\n",
    "\n",
    "        # Appending data\n",
    "        server_data.append(simulation_data)\n",
    "\n",
    "    return pd.DataFrame(server_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk Occupation per Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def get_disk_utilization_data(variation):\n",
    "    server_data = {}\n",
    "\n",
    "    for index, log in enumerate(logs):\n",
    "        # Formatting log\n",
    "        log = list(log)\n",
    "        log[1] = log[1].format(variation)\n",
    "        \n",
    "        # Opening file\n",
    "        server_msgpack_file = (\n",
    "            f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed}/EdgeServer.msgpack\"\n",
    "            if len (log) == 2\n",
    "            else f\"{base_dir}/algorithm={log[0]};dataset={log[1]};seed={seed};replicas={log[2]}/EdgeServer.msgpack\"\n",
    "        )\n",
    "        server_file = open(server_msgpack_file, \"rb\")\n",
    "        server_msgpack = msgpack.load(server_file)\n",
    "        server_df = pd.DataFrame(server_msgpack)\n",
    "\n",
    "        # Collecting information\n",
    "        server_df = server_df[[\"Object\", \"Disk Demand\", \"Time Step\"]]\n",
    "        \n",
    "        server_per_timestep = server_df[server_df[\"Time Step\"] > 0].groupby([\"Time Step\"])[\"Disk Demand\"].sum()\n",
    "\n",
    "        # Persisting information\n",
    "        server_data[algorithm_labels[index]] = server_per_timestep\n",
    "\n",
    "        # Closing file\n",
    "        server_file.close()\n",
    "\n",
    "    return pd.concat(server_data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilitary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_chart(\n",
    "    ax,\n",
    "    title: dict = {},\n",
    "    xticklabels: dict = {},\n",
    "    xlabel: dict = {},\n",
    "    yticklabels: dict = {},\n",
    "    ylabel: str = {},\n",
    "    legend: dict = {},\n",
    "):\n",
    "    \"\"\"Customizes the chart.\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): Axes object.\n",
    "        title (str): Chart title.\n",
    "        xticklabels (list): List of xtick labels.\n",
    "        xlabel (str): Label of the x axis.\n",
    "        yticklabels (list): List of ytick labels.\n",
    "        ylabel (str): Label of the y axis.\n",
    "        legend_labels (list): List of legend labels.\n",
    "    \"\"\"\n",
    "    if title != {}:\n",
    "        ax.set_title(**title)\n",
    "\n",
    "    if xticklabels != {}:\n",
    "        ax.set_xticklabels(**xticklabels)\n",
    "    \n",
    "    if xlabel != {}:\n",
    "        ax.set_xlabel(**xlabel)\n",
    "\n",
    "    if yticklabels != {}:\n",
    "        ax.set_yticklabels(**yticklabels)\n",
    "\n",
    "    if ylabel != {}:\n",
    "        ax.set_ylabel(**ylabel)\n",
    "\n",
    "    if legend != {}:\n",
    "        ax.legend(**legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_difference(data, key):\n",
    "    data = data.reset_index(drop=True)\n",
    "    data[\"Central\"] = data[key] / data[key][0]\n",
    "    data[\"Comm (12%)\"] = data[key] / data[key][1]\n",
    "    data[\"Comm (25%)\"] = data[key] / data[key][2]\n",
    "    data[\"P2P\"] = data[key] / data[key][3]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_string_portrait = \"\"\"\n",
    "\\\\begin{table}\n",
    "\\centering\n",
    "\\caption{%(caption)s}\n",
    "\\label{tab:%(label)s}\n",
    "%(table)s\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "base_string_landscape = \"\"\"\n",
    "\\\\afterpage{\\clearpage\n",
    "\\\\begin{landscape}\n",
    "\\\\begin{table}\n",
    "\\centering\n",
    "\\caption{%(caption)s}\n",
    "\\label{tab:%(label)s}\n",
    "%(table)s\n",
    "\\end{table}\n",
    "\\end{landscape}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def create_grid_of_latex_tables(tables_grid: dict, caption: str, label: str, text_size: str, orientation: str = \"portrait\"):\n",
    "    base_string = base_string_portrait if orientation == \"portrait\" else base_string_landscape\n",
    "\n",
    "    grid = \"\"\n",
    "    for row in tables_grid:\n",
    "        for column in row:\n",
    "            column_size = 1 / len(row)\n",
    "            grid += f\"\\\\begin{{minipage}}[t]{{{column_size}\\\\linewidth}}\\n\\\\centering\\n\\\\{text_size}{{{column}}}\\\\end{{minipage}}\"\n",
    "        grid += \"\\n\\\\hfill\\n\" if orientation == \"portrait\" else \"\\n\\\\vfill\\n\"\n",
    "\n",
    "    table = base_string % {\"caption\": caption, \"label\": label, \"table\": grid}\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading container images metadata\n",
    "container_images = json.load(open(\"datasets/inputs/templates/container_images.json\", \"r\"))\n",
    "\n",
    "# Ignoring registry image\n",
    "container_images = container_images[1:]\n",
    "\n",
    "# Collecting size of images\n",
    "image_sizes = [sum([layer[\"size\"] for layer in image[\"layers\"]])/1000000 for image in container_images]\n",
    "\n",
    "# Plot size distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(image_sizes, bins=10, edgecolor=\"black\")\n",
    "\n",
    "# Customizing chart\n",
    "font_dict = {\n",
    "    \"fontsize\": 14\n",
    "}\n",
    "xticklabels = {\n",
    "    \"labels\": ax.get_xticks(),\n",
    "    \"fontdict\": font_dict\n",
    "}\n",
    "x_label = {\n",
    "    \"xlabel\": \"Size (MiB)\",\n",
    "    \"fontdict\": font_dict\n",
    "}\n",
    "yticklabels = {\n",
    "    \"labels\": ax.get_yticks(),\n",
    "    \"fontdict\": font_dict\n",
    "}\n",
    "y_label = {\n",
    "    \"ylabel\": \"Number of Container Images\",\n",
    "    \"fontdict\": font_dict\n",
    "}\n",
    "customize_chart(ax, xticklabels=xticklabels, xlabel=x_label, yticklabels=yticklabels, ylabel=y_label)\n",
    "\n",
    "# Saving figure\n",
    "plt.savefig(f\"image_size_distribution.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_dfs = {\n",
    "    variation: get_latency_data(variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparative Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: highlight best/specific values from the dataframe: https://stackoverflow.com/questions/65070070/highlight-the-best-value-of-each-row-in-python-pandas-to-latex\n",
    "latency_tables = {}\n",
    "\n",
    "for key, latency_df in latency_dfs.items():\n",
    "    latency_df_table = calculate_relative_difference(latency_df, \"Mean\")\n",
    "    latency_df_table = latency_df_table[[\"Algorithm\", \"Mean\", \"Central\", \"Comm (12%)\", \"Comm (25%)\", \"P2P\"]]\n",
    "    latency_df_table.to_csv(f\"{base_dir}/latency;{key}.csv\", index=False, sep=\";\", decimal=\",\")\n",
    "    latency_tables[key] = latency_df_table\n",
    "\n",
    "latency_tables_grid = [\n",
    "    [\n",
    "        latency_tables[variations[0]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=100;users_per_app=4} \\\\\\\\\\n\\\\toprule\"),\n",
    "        latency_tables[variations[1]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=100;users_per_app=16} \\\\\\\\\\n\\\\toprule\"),\n",
    "    ],\n",
    "    [\n",
    "        latency_tables[variations[2]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=196;users_per_app=4} \\\\\\\\\\n\\\\toprule\"),\n",
    "        latency_tables[variations[3]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=196;users_per_app=16} \\\\\\\\\\n\\\\toprule\"),\n",
    "    ]\n",
    "]\n",
    "\n",
    "latency_tables_grid_latex_string = create_grid_of_latex_tables(latency_tables_grid, \"Latency comparison between algorithms in multiple scenarios.\", \"tab:latency\", \"footnotesize\", \"portrait\")\n",
    "\n",
    "with open(f\"{base_dir}/latency_tables.tex\", \"w\") as f:\n",
    "    f.write(latency_tables_grid_latex_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provisioning Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provisioning_time_dfs = {\n",
    "    variation: get_provisioning_time_data(last_step, variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparative Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provisioning_time_tables = {}\n",
    "\n",
    "for key, provisioning_time_df in provisioning_time_dfs.items():\n",
    "    provisioning_time_table = calculate_relative_difference(provisioning_time_df, \"Mean\")\n",
    "    provisioning_time_table = provisioning_time_table[[\"Algorithm\", \"Mean\", \"Central\", \"Comm (12%)\", \"Comm (25%)\", \"P2P\"]]\n",
    "    provisioning_time_table.to_csv(f\"{base_dir}/provisioning_time;{key}.csv\", index=False, sep=\";\", decimal=\",\")\n",
    "    provisioning_time_tables[key] = provisioning_time_table\n",
    "\n",
    "provisioning_time_tables_grid = [\n",
    "    [\n",
    "        provisioning_time_tables[variations[0]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=100;users_per_app=4} \\\\\\\\\\n\\\\toprule\"),\n",
    "        provisioning_time_tables[variations[1]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=100;users_per_app=16} \\\\\\\\\\n\\\\toprule\"),\n",
    "    ],\n",
    "    [\n",
    "        provisioning_time_tables[variations[2]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=196;users_per_app=4} \\\\\\\\\\n\\\\toprule\"),\n",
    "        provisioning_time_tables[variations[3]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=196;users_per_app=16} \\\\\\\\\\n\\\\toprule\"),\n",
    "    ]\n",
    "]\n",
    "\n",
    "provisioning_time_tables_grid_latex_string = create_grid_of_latex_tables(provisioning_time_tables_grid, \"Provisioning time comparison between algorithms in multiple scenarios.\", \"tab:provisioning-time\", \"footnotesize\", \"portrait\")\n",
    "\n",
    "with open(f\"{base_dir}/provisioning_time_tables.tex\", \"w\") as f:\n",
    "    f.write(provisioning_time_tables_grid_latex_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDF Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how to share labels\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, (key, provisioning_time_df) in enumerate(provisioning_time_dfs.items()):\n",
    "    provisioning_time_df[\"Prov. Time Values\"] = provisioning_time_df[\"Prov. Time Values\"].apply(lambda x: sorted(x))\n",
    "    for index, row in provisioning_time_df.iterrows():\n",
    "        ax[counter // 2][counter % 2].plot(row[\"Prov. Time Values\"], np.linspace(0, 1, len(row[\"Prov. Time Values\"])))\n",
    "        customize_chart(ax[counter // 2][counter % 2], xlabel=\"Provisioning Time (s)\", ylabel=\"Percentage of Reallocations (%)\", title=f\"Scenario: {key}\")\n",
    "\n",
    "fig.legend(algorithm_labels, loc='center', ncols=4, bbox_to_anchor=(0.5, 0.5))\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/provisioning_time.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Reallocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallocations_dfs = {\n",
    "    variation: get_reallocations_data(last_step, variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how to share labels\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, (key, reallocations_df) in enumerate(reallocations_dfs.items()):\n",
    "    reallocations_df = reallocations_df[[\"Algorithm\", \"Only Using Cache\", \"Partially Using Cache\", \"Not Using Cache\"]]\n",
    "    reallocations_df.plot.bar(x=\"Algorithm\", stacked=True, ax=ax[counter // 2][counter % 2], rot=45, legend=False)\n",
    "    customize_chart(ax[counter // 2][counter % 2], xticklabels={\"labels\": algorithm_labels}, xlabel=\"Algorithm\", ylabel=\"Number of Reallocations\", title=f\"Scenario: {key}\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center', ncols=3, bbox_to_anchor=(0.5, 0.5))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/reallocations.pdf\", bbox_inches='tight')\n",
    "\n",
    "# TODO: add labels to the bars (%)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registry Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_usage_dfs = {\n",
    "    variation: get_registry_usage_data(variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot Chart (All Registries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how to share labels\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, (key, registry_usage_df) in enumerate(registry_usage_dfs.items()):\n",
    "    registry_usage_df = registry_usage_df[[\"Algorithm\", \"Values\"]]\n",
    "    ax[counter // 2][counter % 2].boxplot(registry_usage_df[\"Values\"], labels=algorithm_labels)\n",
    "    customize_chart(ax[counter // 2][counter % 2], xlabel=\"Algorithm\", ylabel=\"Percentage of Time Active (%)\", title=f\"Scenario: {key}\")\n",
    "    for tick in ax[counter // 2][counter % 2].get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/registry_usage.pdf\", bbox_inches='tight')\n",
    "\n",
    "# TODO: customize outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot Chart (Only Registries with Some Activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how to share labels\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, (key, registry_usage_df) in enumerate(registry_usage_dfs.items()):\n",
    "    registry_usage_df = registry_usage_df[[\"Algorithm\", \"Values (w/o 0%)\"]]\n",
    "    ax[counter // 2][counter % 2].boxplot(registry_usage_df[\"Values (w/o 0%)\"], labels=algorithm_labels)\n",
    "    customize_chart(ax[counter // 2][counter % 2], xlabel=\"Algorithm\", ylabel=\"Percentage of Time Active (%)\", title=f\"Scenario: {key}\")\n",
    "    for tick in ax[counter // 2][counter % 2].get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/registry_usage_without_0.pdf\", bbox_inches='tight')\n",
    "\n",
    "# TODO: customize outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Registries per Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_registries_dfs = {\n",
    "    variation: get_number_of_registries_data(variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how to share labels\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, (key, number_of_registries_df) in enumerate(number_of_registries_dfs.items()):\n",
    "    number_of_registries_df.plot(ax=ax[counter // 2][counter % 2], legend=False)\n",
    "    customize_chart(ax[counter // 2][counter % 2], xlabel=\"Time Step\", ylabel=\"Number of Registries\", title=f\"Scenario: {key}\")\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, algorithm_labels, loc='center', ncols=4, bbox_to_anchor=(0.5, 0.5))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/number_of_registries.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Utilization per Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_utilization_dfs = {\n",
    "    variation: get_server_utilization_data(variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how to share labels\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, (key, server_utilization_df) in enumerate(server_utilization_dfs.items()):\n",
    "    server_utilization_df.plot(ax=ax[counter // 2][counter % 2], legend=False)\n",
    "    customize_chart(ax[counter // 2][counter % 2], xlabel=\"Time Step\", ylabel=\"Normalized Server Utilization\", title=f\"Scenario: {key}\")\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, algorithm_labels, loc='center', ncols=4, bbox_to_anchor=(0.5, 0.5))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/server_utilization.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variation = \"nodes=100;unique_images=08\"\n",
    "\n",
    "image_replication_data = [\n",
    "    get_image_replication_data(log, target_variation) for log in logs[3:]\n",
    "]\n",
    "\n",
    "headers = [\n",
    "    image_replication_data[index].columns.values.tolist() for index in range(len(image_replication_data))\n",
    "]\n",
    "\n",
    "max_length = max([len(header) for header in headers])\n",
    "header_with_max_length = headers[[len(header) for header in headers].index(max_length)]\n",
    "\n",
    "global_colormap = mpl.colormaps[\"tab20c\"].resampled(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix when it does not start with zero\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stacked area chart for each algorithm in multiple figures using a single legend\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, image_replication_df in enumerate(image_replication_data):\n",
    "    local_color_map = mpl.colors.ListedColormap(global_colormap.colors[:len(image_replication_df.columns)])\n",
    "    image_replication_df.plot.area(ax=ax[counter // 3][counter % 3], legend=False, alpha=0.75, cmap=local_color_map)\n",
    "    ax[counter // 3][counter % 3].set_ylim([0, 1])\n",
    "    ax[counter // 3][counter % 3].invert_yaxis()\n",
    "    customize_chart(ax[counter // 3][counter % 3], xlabel=\"Time Step\", ylabel=\"Percentage of Replicas (%)\", title=f\"Algorithm: {algorithm_labels[counter+3]}\")\n",
    "\n",
    "# create a single colorbar for all figures\n",
    "fig.colorbar(mpl.cm.ScalarMappable(cmap=global_colormap), ax=ax, orientation=\"vertical\", aspect=50, values=header_with_max_length)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/image_replication.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk Utilization per Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_utilization_dfs = {\n",
    "    variation: get_disk_utilization_data(variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how to share labels\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "for counter, (key, disk_utilization_df) in enumerate(disk_utilization_dfs.items()):\n",
    "    disk_utilization_df.plot(ax=ax[counter // 2][counter % 2], legend=False)\n",
    "    customize_chart(ax[counter // 2][counter % 2], xlabel=\"Time Step\", ylabel=\"Disk Utilization (MiB)\", title=f\"Scenario: {key}\")\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, algorithm_labels, loc='center', ncols=4, bbox_to_anchor=(0.5, 0.5))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "plt.savefig(f\"{base_dir}/disk_utilization.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Disk Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_disk_utilization_dfs = {\n",
    "    variation: get_total_disk_utilization_data(variation)\n",
    "    for variation in variations\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use mean values per time step\n",
    "goals_tables = {}\n",
    "\n",
    "for key, latency_df in latency_dfs.items():\n",
    "    #table = latency_df[[\"Algorithm\", \"Sum\"]] + provisioning_time_dfs[key][[\"Sum\"]] + registry_usage_dfs[key][[\"Total\"]] + total_disk_utilization_dfs[key][[\"Total Disk Occupation\"]]\n",
    "    table = pd.concat([latency_df[[\"Algorithm\", \"Sum\"]], provisioning_time_dfs[key][[\"Sum\"]], registry_usage_dfs[key][[\"Total\"]], total_disk_utilization_dfs[key][[\"Total Disk Occupation\"]]], axis=1)\n",
    "    #table = table.rename(columns={\"Sum\": \"Latency\", \"Total\": \"Registry Usage\"})\n",
    "    #table[\"Provisioning Time\"] = table[\"Sum\"]\n",
    "    #table = table.drop(columns=[\"Sum\"])\n",
    "    table.to_csv(f\"{base_dir}/goals;{key}.csv\", index=False, sep=\";\", decimal=\",\")\n",
    "    goals_tables[key] = table\n",
    "    \n",
    "goals_tables_grid = [\n",
    "    [\n",
    "        goals_tables[variations[0]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=100;users_per_app=4} \\\\\\\\\\n\\\\toprule\"),\n",
    "        goals_tables[variations[1]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=100;users_per_app=16} \\\\\\\\\\n\\\\toprule\"),\n",
    "    ],\n",
    "    [\n",
    "        goals_tables[variations[2]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=196;users_per_app=4} \\\\\\\\\\n\\\\toprule\"),\n",
    "        goals_tables[variations[3]].to_latex(index=False, escape=False, column_format=\"lccccc\", float_format=\"{:0.2f}\".format).replace(\"\\\\toprule\", \"\\\\toprule\\n\\multicolumn{5}{c}{Scenario: nodes=196;users_per_app=16} \\\\\\\\\\n\\\\toprule\"),\n",
    "    ]\n",
    "]\n",
    "\n",
    "goals_tables_grid_latex_string = create_grid_of_latex_tables(goals_tables_grid, \"Goals comparison between algorithms in multiple scenarios.\", \"tab:goals\", \"footnotesize\", \"portrait\")\n",
    "\n",
    "with open(f\"{base_dir}/goals_tables.tex\", \"w\") as f:\n",
    "    f.write(goals_tables_grid_latex_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
